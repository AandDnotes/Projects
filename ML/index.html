<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>Machine Learning</title>
    <link href="variables.css" rel="stylesheet" type="text/css" />
    <link href="classes.css" rel="stylesheet" type="text/css" />
    <link rel="icon" href="p144.png">
    <link rel="apple-touch-icon" href=“p144.png"/>
    <link rel="apple-touch-icon" href=“p180.png"/>
  </head>
  <body class="bodyclass">
    <div class="pageclass">
      <header class="headerclass">
        <p class="text-right"><a href="../index.html">ToC</a></p>
        <h1>Machine Learning</h1>
      </header>
      <main class="mainclass">
        <section>
          <p><img class="image-right" src="images/number6.png">As 2023 progressed so the subject of Artificial Intelligence (AI) occurred more and more in the media. Towards the end of the previous year I decided that I would like to know more about AI and, in particular, how the AI software learns. All that I read described applications of AI, along with the benefits and shortcomings, but little about the technology needed to train the model. An online IET talk called 'Demystifying AI', given by AI experts, also provided little to help me understand how a piece of software can be made to learn.</p>
          <p><img class="image-left" src="images/ANN.png">I had a rough idea about the structure of an artificial neural network (ANN), as a collection of 'neurons' (or nodes) with connections between them, and weights on each connection. Luckily I came across the online book '<a href="http://neuralnetworksanddeeplearning.com/index.html"><cite>Neural Networks and Deep Learning</cite></a>' by Micheal Nielsen, published in December 2019. Not only did it describe the process of machine learning for a neural network, it gave the python code to define a network and train it, together with access to the data needed for that training. It then occurred to me that I could produce an AI application and use it to help illustrate a talk on 'how machines learn', since I was sure that others would be as ignorant as me. Once again, luckily, the book used what is probably the simplest application of an ANN, which I thought would be within my limited capability, both of understanding and of coding. The rest of this page describes the project to create a network, train it and produce an application that can be used to run the network.</p>
        </section>
        <section>
          <h2 class="subheadingclass">The Application<img class="image-right" src="images/numbers.png"></h2>
          <p>It seems that there is a large collection of images of hand-written numbers that can be used to train a neural network. The collection of images is known as the 'mnist' database (Modified National Institute of Standards and Technology database), generated by students and researchers. The database consists of 70,000 images, each 28 by 28 pixels, along with the number that the image represents. Nielsen had separated the images into a collection of 50,000 for use as training inputs, a set of 10,000 for testing the network and a further 10,000 as 'validation' images.</p>
          <p>Nielsen also provided python 2 code to load the training data, to define a neural network, use the data to train the network and to test the performance of the network during the training process. He didn't provide the code to actually use the network to recognise an image or the user interface to run it. Therefore the code could only be run through a terminal session (or the python IDLE) and any user interface would be down to me.</p>
          <p>So I set about understanding machine learning and producing an application that I could use as part of a talk to help illustrate the process.</p>
        </section>
        <section>
          <h2 class="subheadingclass">Artificial Neural Networks<img class="image-right" src="images/3layer.png"></h2>
          <p>Let's start by examining the principals of an ANN.</p>
          <p><img class="image-left" src="images/neuron.png">The diagram on the right (taken from Nielsen) illustrates a network with six input neurons, a single hidden layer with nine neurons and then four output neurons. Each neuron in the hidden layer and the output layer has a number of inputs from outer neurons, each with an associated weight. Each neuron also has an associated 'bias' and an activation function that uses the inputs, weights and bias. It is these weights and biases that are modified during the training process. The activation function defines how the inputs, weights and bias are combined to form the output. One of the early functions was known as a Perceptron. This simulated the on/off behaviour of a brain cell and is shown in the diagram. As we will see later, this causes some problems and so alternatives have become the norm.</p>
        </section>
        <section>
          <h2 class="subheadingclass">Training</h2>
          <div class="grid-container">
            <div class="item11">
              <img class="image-left-nm" src="images/deltaOutput.png">
            </div>
            <div class="item12">
              <p>As I said above, training the network involves finding the weights and biases that will give, in this case, the correct classification of the input image. We want a small change in the weights and bias for a neuron to result in a small change to its output, as shown on the left, where j represent the number of connections into the neuron.</p>
            </div>
            <div class="item21">
              <img class="image-left-nm" src="images/perceptron.png">
            </div>
            <div class="item22">
              <p>However, the perceptron output looks like the graph on the left. In other words, small changes in weights and bias will not have any change to the output until the step change is reached, when the output will jump. So the perceptron activation function does not lend itself to the learning process and so some more continuously varying function would work better.</p>
            </div>
            <div class="item31">
              <img class="image-left-nm" src="images/perceptronOutput.png">
            </div>
            <div class="item41">
              <img class="image-left-nm" src="images/sigmoid.png">
            </div>
            <div class="item42">
              <p>Enter the Sigmoid Function. If we had a neuron activation function that looked more like the graph on the left, then small changes in weights and bias would result in small changes in the neuron output. Also, if we can calculate the partial differential of the output with respect to weights and bias, then we can also calculate that change.</p>
              <p>Simplifying the notation by representing the dot product of weights and inputs, plus the bias as 'z', the sigmoid function is shown as &#x3C3;(z). This not only produces the required shape of the curve, but including an exponential makes the differentiation easier.</p>
            </div>
            <div class="item51">
              <img class="image-left-nm" src="images/sigmoidOutput.png">
            </div>
            <div class="item62">
              <p>Starting with our input values, in our case a set of pixel values, we can calculate the output of each neuron in each layer, producing the values from the output layer. Provided we have some values for the weights and biases, then for each neurons in each layer we can compute &#x3C3;(z) for each training input. This is known as Feedforward and starts with randomly generated weights and biases. Actually a random selection from a normal gaussian distribution. We will end up with the number of images that were correctly classified by our network.</p>
            </div>
            <div class="item71">
              <img class="image-left-nm" src="images/QCF.png">
            </div>
            <div class="item72">
              <p><img class="image-right-s" src="images/LS.png">However, just as the perceptron activation function gave a step change in the neuron's output, so the number of correctly classified images is unlikely to change for small changes in weights and biases. Consequently, a 'cost function' is used, the Quadratic Cost Function being shown on the left. This is a multi-dimensional equivalent of a least squares fit to a line and gives us a function that will change with small changes in weights and biases.</p>
            </div>
          </div>
        </section>
        <section>
          <p>So we want to minimise the cost function. This is done using a process called 'Gradient Descent'.</p>
          <p><img class="image-right-s" src="images/decent.png">If the cost function were a surface within a 3-dimensional space and that surface has some minimum, then we want to keep adjusting the weights and biases so as to move us 'downhill' until we reach the bottom. We can do this by:</p>
          <ul class="list">
            <li>Calculating the output error by simply calculating the output of each neuron with the current weights and biases. This is known as 'Feedforward'.</li>
            <li>Starting at the output layer, work backwards, calculating the partial derivatives of the cost with respect to both the weights and the bias, so as to derive the error in each neuron. This is known as 'Backpropagation'.</li>
            <li>Adjust the weights and biases.</li>
            <li>Repeat the process until we reach the bottom.</li>
          </ul>
          <div class="grid-container">
            <div class="item11">
              <img class="image-left-nm" src="images/deltaW.png">
            </div>
            <div class="item212">
              <p>Of course, we need to start the weights and biases with some value and then adjust them after each pass. The process starts by randomly selecting weights and biases from a normal gaussian distribution. Then the adjusted weights and biases are calculated as shown, where &#948; is the error in the output for a neuron (as determined from the backpropagation step), <i>l</i> is the layer and <i>x</i> is the training input. Remember that <i>w</i>, <i>b</i>, &#948; and <i>a</i> are vectors for the whole layer. &#951; is the 'learning rate', which is a hyper parameter (see later) and <i>m</i> is the number of images in the training data.</p>
            </div>
            <div class="item21">
                <img class="image-left-nms" src="images/deltaB.png">
            </div>
          </div>
          <p>We will talk about the images in the training data in a while, but each image consisted of 28x28 pixels, which means that the input layer of the network was 748 neurons. Following Neilsen, I used 100 neurons in a single hidden layer, with then ten neurons in the output layer. That meant 79,400 weights and 110 biases, with 50,000 training images. That is a lot of calculations and so some 'tricks' are used to ease the load and speed up the learning process.</p>
        </section>
        <section>
          <h2 class="subheadingclass">Stochastic Gradient Decent (SGD)</h2>
          <p>Each pass through all training inputs only moves the weights and biases a little, albeit in the right direction. So instead of using all training inputs, the SGD approach uses just a few inputs in each pass, forming what is called a 'mini-batch'. The process is then:</p>
          <ul class="list">
            <li>Randomly select a small number of inputs for a gradient decent pass. Again following Neilsen I used ten images in each mini-batch.</li>
            <li>Randomly select another small set of inputs for the next gradient decent pass.</li>
            <li>Continue until all training inputs have been used.</li>
          </ul>
          <p>Completing, in my case, all 5,000 gradient decent passes is known as an 'epoch'. I then ran the training of my network for 30 epochs.</p>
          <p>Following each epoch, my code (that provided by Neilsen) calculated the accuracy of the model by using 10,000 test images, which were different to those used for the training. At the end of 30 epochs my network to classify hand-written numbers achieved an accuracy of 97.13%.</p>
        </section>
        <section>
          <h2 class="subheadingclass">Hyper Parameters</h2>
          <p>I mentioned that the 'learning rate' was a hyper parameter. When setting up the network there are a number of things that cannot be calculated and so are based on the experience of the developer or via trial and error. These hyper parameters are:</p>
          <ul class="list">
            <li>The number of hidden neurons (100).</li>
            <li>The mini-batch size (10).</li>
            <li>The learning rate (0.5).</li>
            <li>The number of epochs to use (30).</li>
            <li>Which cost function to use (Cross Entropy).</li>
          </ul>
          <p>Not having any experience of neural network modelling or the time to start experimenting, I simply used those hyper parameters suggested by Neilsen. I described the Quadratic Cost Function above because it is easier to understand, but I actually used the Cross Entropy cost function, as recommended by Neilsen (details of the Cross Entropy Cost Function can be found in chapter 3 of Neilsen's book). It seems that the expression for the Cross Entropy cost function does not, like the Quadratic cost function, cause the learning to slow down as we get closer to the minimum error.</p>
        </section>
        <section>
          <h2 class="subheadingclass">The Overall Learning Process</h2>
          <p>So the Stochastic Gradient Decent process for training a neural network (with figures for this hand-written number classifier) is as follows:</p>
          <ul class="list">
            <li>For each epoch of mini-batches (30 epochs, each covering 50,000 training images)</li>
            <ul class="list">
              <li>For each mini-batch of training data (5,000 mini-batches, each of 10 images)</li>
              <ol class="list">
                <li>Input a set of training examples (each image is a set of 784 pixels)</li>
                <li>For each training example: Set the corresponding input activation and perform the following steps:</li>
                <ul class="list">
                  <li>Feedforward: For the neurons in each layer, starting with the second, compute the output</li>
                  <li>Compute the vector of errors for the last layer</li>
                  <li>Backpropagate the error: For each layer, working backwards, compute the vector of errors</li>
                </ul>
                <li>Gradient decent: For each layer, again working backwards, update the weights and the biases, based on the error and a ‘learning rate’</li>
              </ol>
            </ul>
          </ul>
        </section>
        <section>
          <h2 class="subheadingclass">A Python Program</h2>
          <p>As far as converting this theory into practice is concerned, there are two parts; defining and training a neural network to classify images of hand-written numbers and then providing an image to the network and getting the network to classify it.</p>
          <p>Neilsen provided a set of Python2 functions that are needed to load the training and test data, create a neural network and train it. So, within the Python2 IDLE (Integrated Development Environment) I was able to run the following statements:</p>
          <ol class="list">
            <li> import mnist_loader</li>
            <li> training_data, validation_data, test_data = mnist_loader.load_data_wrapper()</li>
            <li>import network</li>
            <li>net = network2.Network([784, 100, 10], cost=network2.CrossEntropyCost)</li>
            <li>net.large_weight_initializer()</li>
            <li>net.SGD(training_data, 30, 10, 0.5, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)</li>
          </ol>
          <p>This loaded the 50,000 training images and 10,000 test images (as well as the 10,000 validation images that I didn't use). Then the network was created with three layers, 784 input neurons, 100 hidden neurons and ten output neurons. It also specified use of the Cross Entropy Cost function. The weights and biases were then initialised and finally the Stochastic Gradient Decent method was used to train the network.</p>
          <p>Each of the 30 epochs took about 30 seconds to execute on the MacBook.</p>
          <p><img class="image-right" src="images/number7.png"> Then it was a question of creating an application that would:</p>
          <ul class="list">
            <li>Display the output from the MacBook's camera.</li>
            <li>Provide a means to capture a still image of the camera output.</li>
            <li>Process the image for input to the neural network.</li>
            <li>Run the network to classify the image and display the result.</li>
          </ul>
          <p>This is a screen grab of the application after it has been asked to classify the image. You will note that this image is different to the one at the top of the page, just to prove that it at least works for two different inputs.</p>
          <p>Since I wanted to use the tkinter and ttk libraries I needed to use Python3, so I had to port the functions needed to run the network from Python2 to Python3. I didn't bother porting the learning functions to Python3 since I could simply run them from Python2 IDLE. Then I used the OpenCV library (which is written in C, but has a Python3 wrapper) to read the images from the camera, display it and do some of the processing (see the next section). I then added buttons to 'freeze' the image, convert it to a form needed to use it as input to the network and then run the network to classify the image. I also displayed some progress text and finally the result. It was also useful to include a reset button that would allowed another image to be captured and processed.</p>
        </section>
        <section>
          <h2 class="subheadingclass">Processing the Input Image</h2>
          <p>Most of my time producing the application was spent converting the image from the camera into a form that was suitable for input to the network. I had read that the mnist database consisted of 28x28 pixel images and so I started by simply scaling the captured image to this size. The classification results were pretty poor, in spite of the >97% accuracy produced during the training.</p>
          <p><img class="image-right" src="images/convert.png">I also knew that the image needed to be in greyscale, that the pixel values needed to be inverted, so that the number was light on a dark background and that the pixel values needed to be in the range 0 to 1 (rather than 0 to 255). I had already filtered out 'grey' values by setting pixels that were less than a certain value to zero, and thus black. I then tried finding the bounds of the digit and centring it within the 28x28 frame. But still not a very successful classifier. However, following further research I discovered that the digits in the mnist images had been scaled to fit in a 20xN box (where N is chosen to maintain the aspect ratio of the digit), which was then centred in a 28x28 image by computing the centre of mass of the pixels, and translating the image so as to position this point at the centre of the 28x28 field.</p>
          <p>The conversion process was then:</p>
          <ul class="list">
            <li>The camera on my MacBook provides an 1,888 x 1,258 pixel RGB image. Using OpenCV I read this as a greyscale and cropped it to 280x280 pixels for display in the central frame of the GUI. Initially I thought that being ten times larger than my final image might help. But it didn't. However, it gave quite a good image size and reading the camera ten times per second produced a reasonably smooth video.</li>
            <li>It was then a fairly easy matter to invert the pixel values, set any pixel value less than 170 to zero and crop it around the drawn digit.</li>
            <li>The resulting image was then resized to have a maximum dimension of 20 pixels, the other dimension being calculated to maintain the aspect ratio.</li>
            <li>Then I added all the pixel values to obtain its 'weight' and found the row and column that was the 'centre of gravity'.</li>
            <li>Finally, the 20xN image was placed in the centre of 28x28 set of zeros and the pixel vlaues normalised to be between zero and one.</li>
          </ul>
          <p>The final step did need a little adjustment on some images. The number 7 was particularly problematic since its CofG can be very high and so, when centred, the bottom of digit fell outside the 28x28 array. So I moved up, left, right or down as necessary to make it all fit.</p>
          <p>The application can still be a little sensitive to the light level, but generally it works.</p>
        </section>
        <section>
          <h2 class="subheadingclass">And So ...</h2>
          <p>This is probably the simplest application of neural networks and the simplest method of training the network that I could have used. But at least I now have an outline understanding of how a piece of software (a machine) can learn. Much more sophisticated techniques have been developed (Nielsen describes some) and much larger, multiple networks have been used in publicly available tools such as ChatGPT and DALL-E. In fact, hardly a day goes past without some mention of Artificial Intelligence in the news.</p>
        </section>
      </main>
      <footer class="footerclass">
        <p>&copy; David James 2023   Last updated: 31st May 2023</p>
      </footer>
    </div>
  </body>
</html>
